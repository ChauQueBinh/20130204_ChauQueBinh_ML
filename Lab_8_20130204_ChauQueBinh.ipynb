{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChauQueBinh/20130204_ChauQueBinh_ML/blob/main/Lab_8_20130204_ChauQueBinh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab deals with **GridSearchCV** for tuning the hyper-parameters of an estimator and applying vectorization techniques to the **movie reviews dataset** for classification task. \n",
        "\n",
        "*   **Deadline: 23:59, 17/4/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_selection import f_classif"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  1.1. Apply **GridSearchCV** for **SVM** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x_dG9SA5OhGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "svm_clf = svm.SVC()\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "\n",
        "grid_search = GridSearchCV(svm_clf, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(metrics.classification_report())\n",
        "# print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "# print(\"Best score: \", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USIOdOhO7Irh",
        "outputId": "4c1ec288-0fe8-4fd2-b8d7-6845c12ef9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'C': 1, 'gamma': 1, 'kernel': 'linear'}\n",
            "Best score:  0.9800000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm, datasets\n",
        "# Load the MNIST dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "UMgcd8q-1DKq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create an SVM model\n",
        "svm = SVC()\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "\n",
        "# Use GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(svm, param_grid, scoring='accuracy', cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and the corresponding accuracy score\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best accuracy score: \", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zAb3MLk1ERJ",
        "outputId": "8ba74a41-5cc9-4242-ea1a-cc99f582a208"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "Best accuracy score:  0.9583333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Predict the labels of the test set using the best SVM model\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Calculate the evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy score: \", accuracy)\n",
        "print(\"Precision score: \", precision)\n",
        "print(\"Recall score: \", recall)\n",
        "print(\"F1 score: \", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66rd_Kq_1ER4",
        "outputId": "5ab5cf70-24e4-4e1e-d6b0-653f1d238984"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score:  1.0\n",
            "Precision score:  1.0\n",
            "Recall score:  1.0\n",
            "F1 score:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.2. Apply **GridSearchCV** for **kNN** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "```\n",
        "where\n",
        "\n",
        "    *  **n_neighbors**: Decide the best k based on the values we have computed earlier.\n",
        "    *  **weights**: Check whether adding weights to the data points is beneficial to the model or not. 'uniform' assigns no weight, while 'distance' weighs points by the inverse of their distances meaning nearer points will have more weight than the farther points.\n",
        "    *  **metric**: The distance metric to be used will calculating the similarity.\n"
      ],
      "metadata": {
        "id": "2g--8cng53sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "from sklearn import datasets\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "k = 3\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "grid_params = {'n_neighbors': [5, 7, 9, 11, 13, 15],\n",
        "               'weights': ['uniform', 'distance'],\n",
        "               'metric': ['minkowski', 'euclidean', 'manhattan']}\n",
        "grid_search = GridSearchCV(knn_clf, grid_params, cv=5)\n",
        "# rf_class=\n",
        "# grid_rf_class= GridSearchCV(estimator=rf_class,param_grid=grid_params,scoring='accuracy',n_jobs=4,cv=10,refit=True, return_train_score=True)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best score: \", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "fX0_kItYPism",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaaf24f6-1741-4cdc-e8bb-cfcaab48a086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'distance'}\n",
            "Best score:  0.9866666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "#code\n",
        "from sklearn import datasets\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load the MNIST dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "grid_params = {\n",
        "    'n_neighbors': [5, 7, 9, 11, 13, 15],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['minkowski', 'euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "# Create a kNN classifier object\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(knn, grid_params, scoring=['accuracy', 'precision', 'recall', 'f1'], refit=False, cv=5)\n",
        "\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and their corresponding score\n",
        "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best Score: \", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the performance of the best estimator on the testing data\n",
        "best_estimator = grid_search.best_estimator_\n",
        "y_pred = best_estimator.predict(X_test)\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 Score: \", f1_score(y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "up7hIt6e4e1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3. Apply GridSearchCV for Random Forest to find the best hyperparameters using the following param_grid.\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}"
      ],
      "metadata": {
        "id": "iexlDH2R4WwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "from sklearn import datasets\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "rf_clf = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(rf_clf, param_grid, cv=5)\n",
        "grid_search.fit(X, y)\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best score: \", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "OlyF9WpN_01p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3182d0c9-68d9-4978-9e09-be0b5c4d5dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'max_depth': 3, 'max_features': 'sqrt', 'max_leaf_nodes': 6, 'n_estimators': 50}\n",
            "Best score:  0.9666666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   1.4 Compare the best obtained results from 1.1 to 1.3 (use PrettyTable to dispaly the results)"
      ],
      "metadata": {
        "id": "G3N7TD7s_3Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "svm_clf = SVC()\n",
        "svm_param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "                  'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "                  'kernel': ['rbf','linear']}\n",
        "\n",
        "svm_grid_search = GridSearchCV(svm_clf, svm_param_grid, cv=5)\n",
        "svm_grid_search.fit(X, y)\n",
        "\n",
        "rf_clf = RandomForestClassifier()\n",
        "rf_param_grid = {'n_estimators': [25, 50, 100, 150],\n",
        "                 'max_features': ['sqrt', 'log2', None],\n",
        "                 'max_depth': [3, 6, 9],\n",
        "                 'max_leaf_nodes': [3, 6, 9]}\n",
        "\n",
        "rf_grid_search = GridSearchCV(rf_clf, rf_param_grid, cv=5)\n",
        "rf_grid_search.fit(X, y)\n",
        "\n",
        "table = PrettyTable(['Model', 'Best hyperparameters', 'Best score'])\n",
        "\n",
        "svm_best_params = svm_grid_search.best_params_\n",
        "svm_best_score = svm_grid_search.best_score_\n",
        "table.add_row(['SVM', svm_best_params, svm_best_score])\n",
        "\n",
        "rf_best_params = rf_grid_search.best_params_\n",
        "rf_best_score = rf_grid_search.best_score_\n",
        "table.add_row(['Random Forest', rf_best_params, rf_best_score])\n",
        "\n",
        "print(table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5xaG3Cn9lbD",
        "outputId": "2668fe96-ef38-495b-d2dd-d496e7cb6a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----------------------------------------------------------------------------------+--------------------+\n",
            "|     Model     |                                Best hyperparameters                               |     Best score     |\n",
            "+---------------+-----------------------------------------------------------------------------------+--------------------+\n",
            "|      SVM      |                      {'C': 1, 'gamma': 1, 'kernel': 'linear'}                     | 0.9800000000000001 |\n",
            "| Random Forest | {'max_depth': 3, 'max_features': 'sqrt', 'max_leaf_nodes': 6, 'n_estimators': 50} | 0.9666666666666668 |\n",
            "+---------------+-----------------------------------------------------------------------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# gr_rf_class= GridSearchCV()\n",
        "# grrf_class.fix(X_train,y_train)\n",
        "# y_predict=gr_rf__class.predict(X_test)"
      ],
      "metadata": {
        "id": "j5eaRpz-_xeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   Apply **GridSearchCV** to different classification algorithms such as **SVM, kNN, LogisticRegression, RandomForest**.\n",
        "*   Compare the results obtained by the best hyperparameters among classification algorithms."
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.1. Apply **GridSearchCV** to **SVM** \n"
      ],
      "metadata": {
        "id": "pnoVB8J4vV36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "-ZTSvsJdvYqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.2. Apply **GridSearchCV** to **kNN** "
      ],
      "metadata": {
        "id": "ol1U_T_NvcqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "kt71yrAoBwYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.3. Apply **GridSearchCV** to **LogisticRegression** "
      ],
      "metadata": {
        "id": "pPkAvse-BxNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "nyYjpHFbB1Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.4. Apply **GridSearchCV** to **RandomForest** "
      ],
      "metadata": {
        "id": "3NjSLo5jB1xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "nktGtM0PB7XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.5. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results) "
      ],
      "metadata": {
        "id": "NZJ3BSHpB9Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "8LS_IYfNCFEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "The dataset consists of **2000 user-created movie reviews** archived on the IMDb(Internet Movie Database). The reviews are equally partitioned into a positive set and a negative set (1000+1000). Each review consists of a plain text file (.txt) and a class label representing the overall user opinion. \n",
        "The class attribute has only two values: **pos** (positive) or **neg** (negative).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.1 Importing additional libraries"
      ],
      "metadata": {
        "id": "lDcxOQRmDz_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk, random\n",
        "nltk.download('movie_reviews')#download movie reviews dataset\n",
        "from nltk.corpus import movie_reviews\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZjyW06skDwvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.2. Movie reviews information"
      ],
      "metadata": {
        "id": "RJpsTIiyv-1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "print(len(movie_reviews.fileids()))\n",
        "print(movie_reviews.categories())\n",
        "print(movie_reviews.words()[:100])\n",
        "print(movie_reviews.fileids()[:10])"
      ],
      "metadata": {
        "id": "5ZE7A0Au1Pg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.3. Create dataset from movie reviews"
      ],
      "metadata": {
        "id": "6pHmMpqMHS23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "random.seed(123)\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "id": "45aY6woMHSH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of Reviews/Documents: {}'.format(len(documents)))\n",
        "print('Corpus Size (words): {}'.format(np.sum([len(d) for (d,l) in documents])))\n",
        "print('Sample Text of Doc 1:')\n",
        "print('-'*30)\n",
        "print(' '.join(documents[0][0][:50])) # first 50 words of the first document"
      ],
      "metadata": {
        "id": "NNke0Da5HqFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_distr = Counter([label for (words, label) in documents])\n",
        "print(sentiment_distr)"
      ],
      "metadata": {
        "id": "vVFUEhnXHsGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.4. Train test split"
      ],
      "metadata": {
        "id": "jTXiEbMzHgVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(documents, test_size = 0.33, random_state=42)"
      ],
      "metadata": {
        "id": "v_-0gZZFHvJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sentiment Distrubtion for Train and Test\n",
        "print(Counter([label for (words, label) in train]))\n",
        "print(Counter([label for (words, label) in test]))"
      ],
      "metadata": {
        "id": "UUGlm5TGHvpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [' '.join(words) for (words, label) in train]\n",
        "X_test = [' '.join(words) for (words, label) in test]\n",
        "y_train = [label for (words, label) in train]\n",
        "y_test = [label for (words, label) in test]"
      ],
      "metadata": {
        "id": "l1ppl_0RHx1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.5. Text Vectorization"
      ],
      "metadata": {
        "id": "7xUaXrjxH6Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(min_df = 10, token_pattern = r'[a-zA-Z]+')\n",
        "X_train_bow = tfidf_vec.fit_transform(X_train) # fit train\n",
        "X_test_bow = tfidf_vec.transform(X_test) # transform test"
      ],
      "metadata": {
        "id": "fzwM0nsIH-8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.6. Apply **SVM** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "BP1vB3loIF28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "b3FHQqh1Hlrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.7. Apply **RandomForest** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "N1Fy8jYBIdxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "Fyfw2R-gIhWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.8. Apply **kNN** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "_btsVKjIIiLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "IZmFu1ZQImhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.9. Apply **LogisticRegression** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "0Ix_HeVGIvDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "sTd3alCMIr-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.10. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results) "
      ],
      "metadata": {
        "id": "nhYF2y6eI058"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}